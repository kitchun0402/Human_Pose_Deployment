import os, sys, time
cwdir = os.path.dirname(os.path.realpath(__file__))
from PoseNet.models.mobilenet_v1 import MobileNetV1, MOBILENET_V1_CHECKPOINTS
from PoseNet.utils import read_cap
import PoseNet
import numpy as np
import torch, cv2
from pyfiglet import Figlet
import json
from utils import build_neck
pyf = Figlet(font = 'slant')

# import your PoseNet Code here
sys.path.insert(1, os.path.join(cwdir, "/PoseNet"))
# import ...
print(f'Successfully imported PoseNet modules from {os.path.join(cwdir,"../HRNet")}')

def LoadModel(weight_dir = "./model_", model_id = 101, output_stride = 16, pose_model_name = "PoseNet", useGPU = False, verbose = False):
    '''
    returns a PyTorch model object
    Args:
        weight_dir: default to "./model_"
        model_id: default to 101
        output_stride: default to 16, must be 8, 16, 32
        pose_model_name: default to "PoseNet"
        useGPU: if true model will use GPU when predicting
    '''
    s_time = time.time()
    model = None

    if pose_model_name == "PoseNet":
        strDevice = 'cpu'
 
        # Put your code to load PoseNet here
        weight_path = os.path.join(weight_dir, MOBILENET_V1_CHECKPOINTS[model_id] + ".pth")
        assert os.path.exists(weight_path), f"The model is not found in {weight_path} "
        print(f'Weight: {weight_path}\n')
        model = MobileNetV1(model_id, output_stride)
        state_dict = torch.load(weight_path)
        # print(state_dict)
        model.load_state_dict(state_dict)

        if useGPU and torch.cuda.is_available():
            strDevice = 'cuda'
            model = model.cuda()
        model.name = 'PoseNet'
        
    else:
        print(f'{pyf.renderText("FATAL")}\n{pose_model_name} not supported.')

    r_time = "{:.2f}".format(time.time() - s_time)
    if verbose:
        print(f'{pyf.renderText(pose_model_name)}\nLoaded in {r_time} second(s).')

    return model

def PredictPose(model, img_path = None, capture = None, ip_webcam = False, scale_factor = 1.0, output_stride = 16, useGPU = False, debug_mode = False):
    '''
    Pose Model Predictor wrapper will return pose data
    Args:
        model: model object generated by LoadModel()
        img_path: path of the image
        useGPU: use GPU when predicting
        debug_mode: print extra information when predicting
    '''
    image_name = None
    if type(capture) == type(None):
        image_name = os.path.basename(img_path).split(".")[0] #image name for saving
        image_name = '0' * (6 - len(image_name)) + str(image_name) #format e.g. 00001

    pose_data = None
    start = time.time()
    if model.name == "PoseNet":
        # Do the magic here
        if type(capture) == type(None):
            input_image, cv2_img, output_scale = PoseNet.read_imgfile(
                img_path, scale_factor=scale_factor, output_stride=output_stride)
        else:
            input_image, cv2_img, output_scale = read_cap(capture, ip_webcam = ip_webcam, scale_factor=scale_factor, output_stride=output_stride)
       
        with torch.no_grad():
            if useGPU and torch.cuda.is_available():
                input_image = torch.Tensor(input_image).cuda()
            else:
                input_image = torch.Tensor(input_image)
            heatmap, offset, displacement_fwd, displacement_bwd = model(input_image) #return corrds: y, x
            pose_scores, keypoint_scores, keypoint_coords = PoseNet.decode_multiple_poses(
                heatmap.squeeze(0),
                offset.squeeze(0),
                displacement_fwd.squeeze(0),
                displacement_bwd.squeeze(0),
                output_stride=output_stride,
                max_pose_detections=10,
                min_pose_score=0.25)
            keypoint_coords *= output_scale

            pose_data = {'poses':[],'compute_time':str(time.time()-start)[:5], 'metadata':{}}

            print(f"Compute time: {pose_data['compute_time']}")
            pose_data_set_list = list(map(lambda set_:list(zip(set_[0],set_[1])),zip(keypoint_coords,keypoint_scores)))
            pose_key_list = ["nose","l_eye","r_eye","l_ear","r_ear","l_shoulder"
                        ,"r_shoulder","l_elbow","r_elbow","l_wrist","r_wrist"
                        ,"l_hip","r_hip","l_knee","r_knee","l_ankle","r_ankle",]
    
            for i in range(len(pose_data_set_list)):
                if sum(keypoint_scores[i])==0:
                    break
                pose_value_list=list(map(lambda pose_set:{'x':pose_set[0][1],'y':pose_set[0][0],'conf':pose_set[1]},pose_data_set_list[i]))
                pose_data['poses'].append(dict(zip(pose_key_list,pose_value_list)))

            #output an annotated image
            # cv2_img = PoseNet.draw_skel_and_kp(
            #     cv2_img, pose_scores, keypoint_scores, keypoint_coords,
            #     min_pose_score=0.25, min_part_score=0.25)
            # cv2.imwrite(image_name + '.jpg', cv2_img)

        for poser in pose_data['poses']:
            l_shoulder_data = poser["l_shoulder"]
            r_shoulder_data = poser["r_shoulder"]
            neck_x, neck_y, neck_conf = build_neck(l_shoulder_data, r_shoulder_data)
            poser["neck"] = {"x":neck_x, "y": neck_y, "conf": neck_conf}

    else:
        print(f'{pyf.renderText("FATAL")}\n{model.name} is not supported in the PredictPose wrapper.')
    
    if cv2_img.ndim == 3: 
        img_h, img_w, img_channels = cv2_img.shape
    else:
        img_h, img_w = cv2_img.shape #grey scale
    pose_data['metadata'] = {
        'width': img_w,
        'height': img_h,
        'pose_model_name': model.name,
        'compute_time': pose_data['compute_time']
    }
    return pose_data, image_name, cv2_img
def save_to_json(pose_data, image_name, output_json_path = "./_testset/json_"):
    '''
    return None
    Args:
        pose_data: generated by PredictPose()
        output_json_path: path to save data in json format
    '''
    if not os.path.isdir(output_json_path):
        os.makedirs(output_json_path)
    with open(os.path.join(output_json_path, image_name + '.json'), 'w') as j:
        json.dump(pose_data, j)
    
if __name__ == '__main__':
    model = LoadModel(verbose= True)
    ls_img = sorted([img.path for img in os.scandir('./players/')if img.path.endswith('.jpg')]) #all images
    for img_path in ls_img:
        print('\n', img_path,'\n')
        pose_data, image_name, cv2_img = PredictPose(model,img_path)
        save_to_json(pose_data, image_name, output_json_path= './players/')
################################################################################
#     ____                  _   __     __
#    / __ \____  ________  / | / /__  / /_
#   / /_/ / __ \/ ___/ _ \/  |/ / _ \/ __/
#  / ____/ /_/ (__  )  __/ /|  /  __/ /_
# /_/    \____/____/\___/_/ |_/\___/\__/
#
################################################################################

# You might or might not need to add a wrapper to the PoseNet model here
